{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission Nicolo LÃ¼scher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "from skimage import io, color, feature, transform, measure, exposure\n",
    "from skimage.filters import gaussian, threshold_otsu\n",
    "from skimage.morphology import dilation, square\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import numpy as np\n",
    "import math\n",
    "import itertools\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load image\n",
    "full_image = io.imread(\"./images/homework images vol 1/\" + os.listdir(\"./images/homework images vol 1/\")[1])\n",
    "dest_size = 250\n",
    "\n",
    "# resize image\n",
    "reduced_image = transform.resize(full_image, (dest_size, dest_size*(full_image.shape[1]/full_image.shape[0])), anti_aliasing=True)\n",
    "# convert to grayscale\n",
    "gray_image = color.rgb2gray(reduced_image)\n",
    "\n",
    "\n",
    "# plotting\n",
    "fig, ax = plt.subplots(1, 2, figsize=(10, 5))\n",
    "ax[0].imshow(full_image)\n",
    "ax[1].imshow(gray_image, cmap='gray')\n",
    "ax[0].set_title('Original Image')\n",
    "ax[1].set_title('Resized Image')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# even out the lighting on the page\n",
    "equalized_image = exposure.equalize_adapthist(gray_image)\n",
    "\n",
    "# plotting\n",
    "fig, ax = plt.subplots(1, 2, figsize=(10, 5))\n",
    "ax[0].imshow(gray_image, cmap='gray')\n",
    "ax[0].set_title('Grayscale Image')\n",
    "ax[1].imshow(equalized_image, cmap='gray')\n",
    "ax[1].set_title('Equalized Image')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "blurred_image = gaussian(gray_image, sigma=1)\n",
    "\n",
    "# threshold image\n",
    "thresh = threshold_otsu(blurred_image)\n",
    "binary_image = blurred_image > thresh\n",
    "\n",
    "# plotting\n",
    "fig, ax = plt.subplots(1, 3, figsize=(10, 5))\n",
    "ax[0].imshow(gray_image, cmap='gray')\n",
    "ax[0].set_title('Grayscale Image')\n",
    "ax[1].imshow(blurred_image, cmap='gray')\n",
    "ax[1].set_title('Blurred Image')\n",
    "ax[2].imshow(binary_image, cmap='gray')\n",
    "ax[2].set_title('Binary Image')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dilate image\n",
    "imedges = feature.canny(binary_image, sigma=5)\n",
    "\n",
    "# plotting\n",
    "plt.title('Canny Edge Detection')\n",
    "plt.imshow(imedges)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_corners(k, imedges):\n",
    "    # perform Hough transform\n",
    "    H, angles, distances = transform.hough_line(imedges)\n",
    "    \n",
    "    # find the indices of the top k highest values in H\n",
    "    flattened_indices = np.argpartition(H.ravel(), -k)[-k:]\n",
    "    indices_2D = np.unravel_index(flattened_indices, H.shape)\n",
    "\n",
    "    # extract and sort the corresponding distances and angles\n",
    "    distances_max = distances[indices_2D[0]]\n",
    "    angles_max = angles[indices_2D[1]]\n",
    "    sorted_indices = np.argsort(H[indices_2D])[::-1]\n",
    "    distances_max = distances_max[sorted_indices]\n",
    "    angles_max = angles_max[sorted_indices]\n",
    "\n",
    "    # initialize lists to store accepted distances and angles\n",
    "    accepted_distances = []\n",
    "    accepted_angles = []\n",
    "\n",
    "    # set thresholds for filtering lines\n",
    "    distance_threshold = 50  # pixels\n",
    "    angle_threshold = 0.4  # radians\n",
    "\n",
    "    # plotting\n",
    "    fig, (ax0, ax1) = plt.subplots(ncols=2, nrows=1, figsize=(15, 8))\n",
    "    ax0.set(xlabel=\"x [pixels]\", ylabel=\"y [pixels]\", title=\"Original image with detected lines\")\n",
    "    ax0.imshow(imedges, cmap=\"gray\")\n",
    "    Himage = ax1.imshow(H, extent=(angles[0], angles[-1], distances[0], distances[-1]), origin=\"lower\", aspect=\"auto\")\n",
    "    ax1.set(xlabel=\"angle [rad]\", ylabel=\"d [pixels]\", title=\"H: Hough space accumulator\")\n",
    "    plt.colorbar(Himage)\n",
    "\n",
    "    # loop through the sorted highest values and filter lines\n",
    "    for i in range(k):\n",
    "        d = distances_max[i]\n",
    "        theta = angles_max[i]\n",
    "    \n",
    "        # check if the line is too close or parallel to already accepted lines\n",
    "        if len(accepted_distances) > 0:\n",
    "            distances_diff = np.abs(np.abs(d) - np.abs(np.array(accepted_distances)))\n",
    "            angles_diff = [np.arccos(np.cos(theta - accepted_theta)) for accepted_theta in accepted_angles]\n",
    "            if any((distances_diff < distance_threshold) & ((np.array(angles_diff) < angle_threshold) | (np.array(angles_diff) > np.pi - angle_threshold))):\n",
    "                continue\n",
    "    \n",
    "        # add the line to the list of accepted lines\n",
    "        accepted_distances.append(d)\n",
    "        accepted_angles.append(theta)\n",
    "    \n",
    "        # plot a white rectangle over the maximum in Hough space\n",
    "        ax1.plot(theta, d, \"ws\", fillstyle=\"none\")\n",
    "    \n",
    "        # draw the line in image space\n",
    "        p1 = np.array([d * np.cos(theta), d * np.sin(theta)])\n",
    "        linedir = np.array([np.cos(theta + np.pi / 2), np.sin(theta + np.pi / 2)])\n",
    "        p0 = p1 - linedir * 200\n",
    "        p2 = p1 + linedir * 200\n",
    "        ax0.plot([p0[0], p2[0]], [p0[1], p2[1]], scalex=False, scaley=False)\n",
    "\n",
    "    # initialize list to store intersection points\n",
    "    intersections = []\n",
    "\n",
    "    # loop through all pairs of lines to find intersections\n",
    "    for i in range(len(accepted_distances)):\n",
    "        for j in range(i + 1, len(accepted_distances)):\n",
    "            d1, theta1 = accepted_distances[i], accepted_angles[i]\n",
    "            d2, theta2 = accepted_distances[j], accepted_angles[j]\n",
    "        \n",
    "            # direction vectors\n",
    "            dir1 = np.array([np.cos(theta1 + np.pi / 2), np.sin(theta1 + np.pi / 2)])\n",
    "            dir2 = np.array([np.cos(theta2 + np.pi / 2), np.sin(theta2 + np.pi / 2)])\n",
    "        \n",
    "            # points on the lines\n",
    "            p1 = np.array([d1 * np.cos(theta1), d1 * np.sin(theta1)])\n",
    "            p2 = np.array([d2 * np.cos(theta2), d2 * np.sin(theta2)])\n",
    "        \n",
    "            # Solve for intersection\n",
    "            A = np.vstack([dir1, -dir2]).T\n",
    "            b = p2 - p1\n",
    "            if np.linalg.matrix_rank(A) == 2:  # lines are not parallel\n",
    "                t, s = np.linalg.solve(A, b)\n",
    "                intersection = p1 + t * dir1\n",
    "                intersections.append(intersection)\n",
    "\n",
    "    # get the dimensions of the image\n",
    "    height, width = imedges.shape\n",
    "\n",
    "    def distance(p1, p2):\n",
    "        return math.dist(p1, p2)\n",
    "\n",
    "    def inside_image_percentage(points, width, height):\n",
    "        x_coords, y_coords = zip(*points)\n",
    "        x_min, x_max = min(x_coords), max(x_coords)\n",
    "        y_min, y_max = min(y_coords), max(y_coords)\n",
    "    \n",
    "        # Calculate the area of the bounding box inside the image\n",
    "        x_min_clamped = max(0, x_min)\n",
    "        x_max_clamped = min(width, x_max)\n",
    "        y_min_clamped = max(0, y_min)\n",
    "        y_max_clamped = min(height, y_max)\n",
    "    \n",
    "        if x_min_clamped < x_max_clamped and y_min_clamped < y_max_clamped:\n",
    "            inside_area = (x_max_clamped - x_min_clamped) * (y_max_clamped - y_min_clamped)\n",
    "            total_area = (x_max - x_min) * (y_max - y_min)\n",
    "            return inside_area / total_area\n",
    "        return 0\n",
    "\n",
    "    def best_trapezoid_or_square(intersections, width, height):\n",
    "        best_score = float('inf')\n",
    "        best_combination = None\n",
    "        \n",
    "        for combination in itertools.combinations(intersections, 4):\n",
    "            # Check if the bounding box of the combination is mostly inside the image\n",
    "            if inside_image_percentage(combination, width, height) < 0.8:  # 80% threshold\n",
    "                continue\n",
    "            \n",
    "            distances = sorted([distance(combination[i], combination[j]) for i in range(3) for j in range(i+1, 4)])\n",
    "            \n",
    "            # Score based on how square/trapezoid-like the combination is\n",
    "            score = abs(distances[0] - distances[1]) + abs(distances[0] - distances[2]) + abs(distances[0] - distances[3]) + abs(distances[4] - distances[5])\n",
    "            \n",
    "            if score < best_score:\n",
    "                best_score = score\n",
    "                best_combination = combination\n",
    "\n",
    "        if best_combination is None:\n",
    "            return []\n",
    "        return list(best_combination)\n",
    "\n",
    "\n",
    "    intersections = best_trapezoid_or_square(np.array(intersections), width, height)\n",
    "\n",
    "    return intersections\n",
    "\n",
    "# Initial value for k\n",
    "k = 1\n",
    "\n",
    "# Loop until 4 corners are found\n",
    "while True:\n",
    "    intersections = find_corners(k, imedges)\n",
    "    if len(intersections) == 4:\n",
    "        break\n",
    "    k += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create figure and axes\n",
    "fig, ax = plt.subplots(1)\n",
    "\n",
    "# rescale points to match the original image\n",
    "intersections = np.array(intersections) * (full_image.shape[0] / dest_size)\n",
    "\n",
    "# display the image\n",
    "ax.imshow(full_image)\n",
    "\n",
    "# calculate the centroid\n",
    "centroid = np.mean(intersections, axis=0)\n",
    "\n",
    "# sort the points based on the angle with the centroid\n",
    "sorted_points = sorted(intersections, key=lambda point: -np.arctan2(point[1] - centroid[1], point[0] - centroid[0]))\n",
    "\n",
    "# create a rectangle patch\n",
    "rect = patches.Polygon(sorted_points, closed=True, edgecolor='r', facecolor='none')\n",
    "\n",
    "# add the patch to the axes\n",
    "ax.add_patch(rect)\n",
    "\n",
    "# plotting\n",
    "ax.set_title('Detected Rectangle')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a, b, c, d = sorted_points[:4]\n",
    "# size of the output image (A4 paper size)\n",
    "w,h = 210 * 4, 297 * 4\n",
    "A = np.array([0,h])\n",
    "B = np.array([w,h])\n",
    "C = np.array([w,0])\n",
    "D = np.array([0,0])\n",
    "invtf = transform.estimate_transform(\n",
    "    \"projective\", src=np.vstack((A, B, C, D)), dst=np.vstack((a, b, c, d))\n",
    ")\n",
    "\n",
    "# wrap the image\n",
    "warped = transform.warp(full_image, inverse_map=invtf, output_shape=(h, w))\n",
    "\n",
    "# set the background to the average color of the image\n",
    "warped[warped.sum(axis=2) == 0] = warped.mean(axis=(0, 1))\n",
    "\n",
    "warped = color.rgb2gray(warped)\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(ncols=2, figsize=(15, 8))\n",
    "ax1.imshow(warped)\n",
    "ax2.imshow(transform.resize(warped, (210*2, 297*2)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the height and width of the image\n",
    "height, width = warped.shape\n",
    "\n",
    "# calculate the aspect ratio\n",
    "aspect_ratio = width / height\n",
    "\n",
    "# check if the aspect ratio is greater than 1\n",
    "if aspect_ratio > 1:\n",
    "    print('The image is more likely to be landscape')\n",
    "    wrapped = transform.resize(warped, (210*2, 297*2))\n",
    "else:\n",
    "    print('The image is more likely to be portrait')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# boost contrast\n",
    "boosted_contrast = np.clip(warped * 1.5, 0, 1)\n",
    "\n",
    "# binarize image\n",
    "thresh = threshold_otsu(boosted_contrast)\n",
    "binary_image = boosted_contrast > thresh\n",
    "\n",
    "# invert image\n",
    "gray_image = 1 - binary_image\n",
    "\n",
    "# dilate image\n",
    "dilated_image = dilation(gray_image, square(4))\n",
    "\n",
    "# plotting\n",
    "fig, ax = plt.subplots(1, 4, figsize=(10, 5))\n",
    "ax[0].imshow(warped)\n",
    "ax[0].set_title('Original Image')\n",
    "ax[1].imshow(binary_image)\n",
    "ax[1].set_title('Binary Image')\n",
    "ax[2].imshow(gray_image)\n",
    "ax[2].set_title('Inverted Image')\n",
    "ax[3].imshow(dilated_image)\n",
    "ax[3].set_title('Dilated Image')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform connected component analysis\n",
    "labeled_image = measure.label(dilated_image)\n",
    "\n",
    "# plotting\n",
    "fig, ax = plt.subplots(1, 2, figsize=(10, 5))\n",
    "ax[0].imshow(dilated_image)\n",
    "ax[0].set_title('Dilated Image')\n",
    "ax[1].imshow(labeled_image)\n",
    "ax[1].set_title('Labeled Image')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop through all connected components\n",
    "bounding_boxes = []\n",
    "for region in measure.regionprops(labeled_image):\n",
    "        \n",
    "        # skip too small and too large regions\n",
    "        if region.area < 60 or region.area > 10000:\n",
    "            continue\n",
    "        \n",
    "        # extract the bounding box coordinates\n",
    "        minr, minc, maxr, maxc = region.bbox\n",
    "\n",
    "        # skip images that are not roughly square\n",
    "        if (maxr - minr) / (maxc - minc) > 4 or (maxc - minc) / (maxr - minr) > 4:\n",
    "            continue\n",
    "\n",
    "        # check if the bounding box is too close to the edge of the image\n",
    "        if minr < 10 or minc < 10 or maxr > dilated_image.shape[0] - 10 or maxc > dilated_image.shape[1] - 10:\n",
    "            continue\n",
    "        \n",
    "        # add the bounding box coordinates to the list with a 10 pixel margin\n",
    "        bounding_boxes.append((minr - 10, minc - 10, maxr + 10, maxc + 10))\n",
    "\n",
    "# plotting\n",
    "fig, ax = plt.subplots(1, figsize=(10, 5))\n",
    "ax.imshow(dilated_image)\n",
    "\n",
    "# loop through the bounding boxes and draw them on the image\n",
    "for minr, minc, maxr, maxc in bounding_boxes:\n",
    "    rect = patches.Rectangle((minc, minr), maxc - minc, maxr - minr, linewidth=1, edgecolor='r', facecolor='none')\n",
    "    ax.add_patch(rect)\n",
    "\n",
    "ax.set_title('Bounding Boxes')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accepted_bounding_boxes = []\n",
    "\n",
    "# loop through the bounding boxes\n",
    "\n",
    "for minr, minc, maxr, maxc in bounding_boxes:\n",
    "        \n",
    "        # check if the bounding box is too close to an already accepted bounding box\n",
    "        if len(accepted_bounding_boxes) > 0:\n",
    "            distances = np.array([np.abs(minr - accepted_minr) for accepted_minr, _, _, _ in accepted_bounding_boxes])\n",
    "            if any(distances < 10):\n",
    "                continue\n",
    "        \n",
    "        # add the bounding box to the list of accepted bounding boxes\n",
    "        accepted_bounding_boxes.append((minr, minc, maxr, maxc))\n",
    "\n",
    "# plotting\n",
    "fig, ax = plt.subplots(1, len(bounding_boxes), figsize=(10, 5))\n",
    "for i, (minr, minc, maxr, maxc) in enumerate(bounding_boxes):\n",
    "    ax[i].imshow(dilated_image[minr:maxr, minc:maxc])\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CompVis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
